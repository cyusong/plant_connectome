Systems biology and mathematical approaches are required for understanding how genetic regulatory networks process information from the environment. A typical genetic communication channel is conformed by: 1) an encoder, which is a specific membrane receptor that perceives the environmental information in the form of a concentration of a specific phytohormone. In the particular case of the ethylene signaling pathway, the encoder is the ETR1,2 specific receptor to ethylene; 2) a transmitting pathway, which is a signaling pathway. In the case, the ethylene signaling pathway; 3) a decoder, which is the molecular transcriptional machinery associated with the ERF1 and downstream genes and 4) an effector, which is the molecular translational machinery associated to the ethylene genetic network. Every communication channel is subject to noise, i.e., any physicochemical process that can alter the message carried from the encoder to the decoder and effector. Noise introduces a certain amount of uncertainty in any message spread through the communication channel. The amount of uncertainty in the content of a message is measured with the Shannon's entropy function H and, consequently, the amount of information actually carried by the message can be measured with the information function I = Hmax-H. Genetic networks are composed of a relative low and fluctuating amount of molecules and this characteristic, together with the effect of noise, produces a genetic response at time t with a probability p(t) of being correct with respect to the input message, and a probability 1-p(t) of been incorrect. From these probability values, H and I functions can be evaluated and, for the first time, it is possible to assign a measure of information content to each message associated to a given concentration of phytohormone. This type of analysis can be applied to any other plant genetic regulatory network.

ETR1,2: !encodes! ethylene 
ethylene signaling pathway: !transmits! message 
ERF1: !decodes! message 
message: !carries! information 
Shannon's entropy function H: !measures! uncertainty 
information function I: !calculates! content